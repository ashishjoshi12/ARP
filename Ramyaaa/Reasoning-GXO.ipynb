{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa913bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\melod\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.7.tar.gz (66.7 MB)\n",
      "     ---------------------------------------- 66.7/66.7 MB 3.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\melod\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\melod\\anaconda3\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\melod\\anaconda3\\lib\\site-packages (from pdf2image) (9.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Collecting typing-extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from llama-cpp-python) (2.11.3)\n",
      "Collecting diskcache>=5.6.1\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.5/45.5 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (7.31.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (6.15.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.4)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: backcall in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: colorama in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (67.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\melod\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.0.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: jupyter_core in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\melod\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from jupyter_core->nbformat>=4.2.0->ipywidgets) (302)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\melod\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\melod\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\melod\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\melod\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\melod\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\melod\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\melod\\anaconda3\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\melod\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'error'\n",
      "Failed to build llama-cpp-python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for llama-cpp-python (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  *** scikit-build-core 0.10.7 using CMake 3.31.4 (wheel)\n",
      "  *** Configuring CMake...\n",
      "  2025-02-04 23:13:00,516 - scikit_build_core - WARNING - Can't find a Python library, got libdir=None, ldlibrary=None, multiarch=None, masd=None\n",
      "  loading initial cache file C:\\Users\\melod\\AppData\\Local\\Temp\\tmpwsx0pt38\\build\\CMakeInit.txt\n",
      "  -- Building for: NMake Makefiles\n",
      "  CMake Error at CMakeLists.txt:3 (project):\n",
      "    Running\n",
      "  \n",
      "     'nmake' '-?'\n",
      "  \n",
      "    failed with:\n",
      "  \n",
      "     no such file or directory\n",
      "  \n",
      "  \n",
      "  CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage\n",
      "  CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage\n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  \n",
      "  *** CMake configuration failed\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for llama-cpp-python\n",
      "ERROR: Could not build wheels for llama-cpp-python, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "#pip install pdf2image pytesseract opencv-python ollama pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217090a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import ollama\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b50636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF to images\n",
    "def pdf_to_images(pdf_path):\n",
    "    return convert_from_path(pdf_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e30b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text using Tesseract OCR\n",
    "def extract_text_from_images(images):\n",
    "    extracted_text = \"\"\n",
    "    for img in images:\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        extracted_text += text + \"\\n\"\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a46b150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tables using OpenCV & Tesseract\n",
    "def extract_tables_from_images(images):\n",
    "    tables = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        table_text = pytesseract.image_to_string(thresh, config=\"--psm 6\")\n",
    "\n",
    "        # Convert text into structured table format\n",
    "        table_lines = [line.split() for line in table_text.split(\"\\n\") if line.strip()]\n",
    "        if table_lines:\n",
    "            df = pd.DataFrame(table_lines)\n",
    "            tables.append(df)\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240d23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDF and extract structured data\n",
    "def process_pdf(pdf_path):\n",
    "    images = pdf_to_images(pdf_path)\n",
    "    text = extract_text_from_images(images)\n",
    "    tables = extract_tables_from_images(images)\n",
    "    return {\"text\": text, \"tables\": tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f9248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identification Layer\n",
    "def identLayer(text, table_data, table_item):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI analyst that extracts insights by reasoning over structured data.\n",
    "\n",
    "    Extracted Information From The Document is:\n",
    "    {text}\n",
    "\n",
    "    Extracted Table Data:\n",
    "    {json.dumps([table.to_dict() for table in table_data], indent=2)}\n",
    "\n",
    "    Fetch table line item \"{table_item}\" and identify its trend over the specified period in the document.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8cd13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdentLayerResponse(pdf_path, table_item):\n",
    "    data = process_pdf(pdf_path)\n",
    "    response = infoExtLayer(data[\"text\"], data[\"tables\"], table_item)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c9df90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Extraction Layer\n",
    "def infoExtLayer(text, table_data, table_item):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI analyst that extracts insights by reasoning over structured data.\n",
    "\n",
    "    Extracted Information From The Document is:\n",
    "    {text}\n",
    "\n",
    "    Extracted Table Data:\n",
    "    {json.dumps([table.to_dict() for table in table_data], indent=2)}\n",
    "\n",
    "    Focus only on the specific table line item: \"{table_item}\".\n",
    "    - Identify this item in the Income Statement Summary table.\n",
    "    - Collect all the related information related to \"{table_item}\" in the extracted text.\n",
    "    - Provide all the structured facts and insights from the document and respond concisely.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46c6ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfoExtLayerResponse(pdf_path, table_item):\n",
    "    data = process_pdf(pdf_path)\n",
    "    response = infoExtLayer(data[\"text\"], data[\"tables\"], table_item)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6322efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reasoning/Implication Layer\n",
    "def reasLayer(text, table_item):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI analyst that extracts insights by reasoning over structured data.\n",
    "\n",
    "    Given below are the facts and insights gathered from the given document about the line item {table_item}.\n",
    "    {text}\n",
    "\n",
    "    Focus only on the specific table line item: \"{table_item}\" and using the factors that affect it :\n",
    "    - Identify the factors affecting {table_item} and correlate a few references of those factors from the text.\n",
    "    - Pick up cause-effect relationships from the text corresponding to the factors present in the rules.\n",
    "    - Collect a set of implications or reasons that attributed to the observed change in {table_item}.\n",
    "    - List them concisely with quoted reference to statistical data and informational evidence from the text.\n",
    "    - Reasoning to be confined only to the content of the pdf and its statistical evidences. Any information having \n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c80e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReasLayerResponse(rules, text, table_item):\n",
    "    response = reasLayer(rules, text, table_item)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d930d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = getIdentLayerResponse(\"gxo.pdf\", \"Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79116cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_response = getInfoExtLayerResponse(\"gxo.pdf\", trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed1725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The increase in revenue is primarily attributed to the following factors:  \n",
      "\n",
      "1. **Acquisitions**  \n",
      "   - The **Clipper Acquisition** contributed **$378 million** in revenue for periods that were not comparable year-over-year.  \n",
      "   - The **PFS Acquisition** added **$82 million** to the total revenue.  \n",
      "\n",
      "2. **Geographic Growth**  \n",
      "   - Revenue growth in **Continental Europe** played a significant role in the overall increase.  \n",
      "\n",
      "3. **Foreign Currency Movements**  \n",
      "   - Favorable foreign exchange fluctuations contributed **$140 million** to the revenue increase.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "getReasLayerResponse(layer1_response, trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = getIdentLayerResponse(\"gxo.pdf\", \"Operating Income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6292c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_response = getInfoExtLayerResponse(\"gxo.pdf\", trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d2b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The increase in **Operating Income** is primarily due to the following factors:  \n",
      "\n",
      "### **Factors Contributing to the Increase in Operating Income:**  \n",
      "1. **Revenue Growth**  \n",
      "   - Operating income increased as a result of **higher revenue**, driven by the Clipper and PFS acquisitions, as well as growth in Continental Europe.  \n",
      "\n",
      "2. **Lower Transaction and Integration Costs**  \n",
      "   - Transaction and integration costs **decreased by $27 million**, from **$61 million in 2022 to $34 million in 2023**. The reduction was due to lower costs associated with integrating Clipper and PFS acquisitions.  \n",
      "\n",
      "3. **Higher Selling, General, and Administrative (SG&A) Expenses**  \n",
      "   - SG&A expenses increased **by 13% ($112 million)** due to **higher personnel costs** and **bad debt expenses**. However, this was offset by business growth.  \n",
      "\n",
      "4. **Increase in Depreciation and Amortization**  \n",
      "   - Depreciation and amortization expenses rose **by $32 million (10%)**, primarily due to the **Clipper acquisition**.  \n",
      "\n",
      "5. **Restructuring Costs Stayed Constant**  \n",
      "   - Restructuring costs remained unchanged at **$32 million**, with expenses related to centralization initiatives and impairment charges.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "getReasLayerResponse(layer1_response, trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2fba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = getIdentLayerResponse(\"gxo.pdf\", \"Net Income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_response = getInfoExtLayerResponse(\"gxo.pdf\", trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea80473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The increase in **Net Income** is primarily due to the following factors:  \n",
      "\n",
      "### **Factors Contributing to the Increase in Net Income:**  \n",
      "1. **Revenue Growth**  \n",
      "   - Increased revenue from the **Clipper and PFS acquisitions** and **growth in Continental Europe** contributed to higher net income.  \n",
      "\n",
      "2. **Lower Transaction and Integration Costs**  \n",
      "   - These costs decreased **by $27 million**, reducing overall expenses.  \n",
      "\n",
      "3. **Lower Effective Tax Rate**  \n",
      "   - The **effective tax rate decreased from 24.2% in 2022 to 12.4% in 2023**, mainly due to tax benefits from intangible assets and the release of valuation allowances. This resulted in a **$31 million reduction in income tax expense**.  \n",
      "\n",
      "### **Factors Offsetting the Increase in Net Income:**  \n",
      "1. **Higher Interest Expense**  \n",
      "   - Interest expense **increased by $24 million (83%)** due to the Clipper acquisition debt being **outstanding for a full year** and rising variable interest rates.  \n",
      "\n",
      "2. **Lower Other Income**  \n",
      "   - Other income, net, **decreased by $50 million (98%)**, mainly due to **lower pension income and foreign currency losses**.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "getReasLayerResponse(layer1_response, trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "300cafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inductive Reasoning/Implication Layer\n",
    "def reasLayerInductive(text, table_item):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI analyst that extracts insights by reasoning over structured data.\n",
    "\n",
    "    Given below are the facts and insights gathered from the given document about the line item {table_item}.\n",
    "    {text}\n",
    "\n",
    "    Focus only on the specific table line item: \"{table_item}\" and using the factors that affect it :\n",
    "    - Identify the factors affecting {table_item} and correlate a few references of those factors from the text.\n",
    "    - Pick up cause-effect relationships from the text corresponding to the factors present in the rules.\n",
    "    - Collect a set of implications or reasons that attributed to the observed change in {table_item}.\n",
    "    - List them concisely with quoted reference to statistical data and informational evidence from the text.\n",
    "    - Reasoning to be confined only to the content of the pdf and its statistical evidences. Any information having \n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59583857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReasLayerInductiveResponse(rules, text, table_item):\n",
    "    response = reasLayer(rules, text, table_item)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = getIdentLayerResponse(\"gxo.pdf\", \"Net Income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_response = getInfoExtLayerResponse(\"gxo.pdf\", trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c123db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hereâ€™s an analysis for the **Net Income** change based on the document:  \n",
      "\n",
      "### **Analysis of Net Income**  \n",
      "\n",
      "1. **Pattern in Revenue Growth and Acquisitions**  \n",
      "   - Revenue increased by **9% ($785 million)** in 2023, primarily due to the **Clipper** and **PFS** acquisitions.  \n",
      "   - Acquisitions contributed a **combined $460 million** to revenue, suggesting a **trend where strategic acquisitions drive financial growth**.  \n",
      "\n",
      "2. **Trend in Tax Benefits**  \n",
      "   - The **effective tax rate dropped from 24.2% to 12.4%**, resulting in a **$31 million reduction in income tax expense**.  \n",
      "   - This suggests a **potential pattern where tax optimization strategies contribute to net income growth** across fiscal years.  \n",
      "\n",
      "3. **Interest Expense and Debt Patterns**  \n",
      "   - Interest expense **increased by 83% ($24 million)** due to debt from the **Clipper acquisition and rising interest rates**.  \n",
      "   - If this trend continues, **future net income growth could be constrained by increasing financing costs**.  \n",
      "\n",
      "4. **Volatility in Other Income**  \n",
      "   - Other income, net, **decreased by 98% ($50 million)** due to **lower pension income and foreign exchange losses**.  \n",
      "   - This suggests an **unpredictable factor affecting net income**, making future earnings subject to external financial conditions.  \n",
      "\n",
      "### **Generalized Insights (Inductive Conclusions)**  \n",
      "- **Acquisition-driven revenue growth has positively influenced net income**, but rising **interest expenses and external financial losses** may moderate future gains.  \n",
      "- **Tax optimization strategies have significantly boosted net income**, which may be a recurring financial strategy.  \n",
      "- **Future net income growth depends on balancing acquisition gains with financial stability** (interest costs, foreign exchange risks).  \n",
      "\n",
      "Would you like further insights on any specific aspect?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "getReasLayerResponse(layer1_response, trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019af536",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different reasoning techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
