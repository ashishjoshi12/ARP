{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MB5pkUBTPxT9"},"outputs":[],"source":["#installing ollama\n","#!pip install ollama\n","!curl -fsSL https://ollama.com/install.sh | sh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo5wtP9yRXMO"},"outputs":[],"source":["#starting ollama server locally\n","import subprocess\n","import time\n","process = subprocess.Popen(\"ollama serve\", shell=True)\n","time.sleep(5)  # Wait for 5 seconds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnT_dwq7P5VC"},"outputs":[],"source":["#pulling llama3 using ollama\n","!ollama pull llama3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zlmNn4VpRB0f"},"outputs":[],"source":["#testing llama 3 is availble\n","!ollama list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMg5iCGIPAsG"},"outputs":[],"source":["!pip install langchain_community langchain langchain-openai langchain_pinecone langchain[docarray] docarray pydantic==1.10.8 pytube python-dotenv tiktoken pinecone-client scikit-learn ruff pypdf faiss-cpu\n"]},{"cell_type":"code","source":["import os\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.llms import Ollama\n","from langchain_openai.chat_models import ChatOpenAI\n","from langchain_community.embeddings import OllamaEmbeddings\n","from langchain_openai.embeddings import OpenAIEmbeddings\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain.prompts import PromptTemplate\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain_community.vectorstores import DocArrayInMemorySearch\n","from operator import itemgetter"],"metadata":{"id":"bMZmbjeGJll_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pm0gZk1Oi4e"},"outputs":[],"source":["\n","#setting up model dynamically\n","#from dotenv import load_dotenv\n","\n","#load_dotenv()\n","\n","#OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n","#MODEL = \"gpt-3.5-turbo\"\n","#MODEL = \"mixtral:8x7b\"\n","MODEL = \"llama3\"\n","\n","VECTOR_STORE = \"default\"\n","#VECTOR_STORE = \"FAISS\"\n","#VECTOR_STORE = \"pinecone\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XvY1Gw4OzGe"},"outputs":[],"source":["#loading model based on selection\n","if MODEL.startswith(\"gpt\"):\n","    model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=MODEL)\n","    embeddings = OpenAIEmbeddings()\n","else:\n","    model = Ollama(model=MODEL)\n","    embeddings = OllamaEmbeddings(model=MODEL)\n","\n","#testing model invoke\n","model.invoke(\"what is ML\")"]},{"cell_type":"code","source":["#creating parser\n","parser = StrOutputParser()\n","\n","chain = model | parser\n","\n","#testing model invoke with parser\n","chain.invoke(\"what is ML\")"],"metadata":{"id":"0L64O9tvKJQI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#creating template\n","template = \"\"\"\n","Answer the question based on the context below. If you can't\n","answer the question, reply \"I don't know\".\n","\n","Context: {context}\n","\n","Question: {question}\n","\"\"\"\n","\n","prompt = PromptTemplate.from_template(template)\n","\n","#testing prompt\n","prompt.format(context=\"Here is some context\", question=\"Here is a question\")"],"metadata":{"id":"jZC8dhidKx8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading pdf files\n","loader = PyPDFLoader(\"/content/gxocompany.pdf\")\n","pages = loader.load_and_split()\n","pages"],"metadata":{"id":"MassZcwpLBMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading vector store based on selection\n","if VECTOR_STORE == \"FAISS\":\n","    vectorstore = FAISS.from_documents(pages, embeddings)\n","else:\n","    vectorstore = DocArrayInMemorySearch.from_documents(pages, embedding=embeddings, verbose=True)"],"metadata":{"id":"-7ibIrIuLnvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#setting up retriver\n","retriever = vectorstore.as_retriever()\n","\n","#testing retriver\n","retriever.invoke(\"balance sheets\")"],"metadata":{"id":"zdUxpw7TL61L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chaining all operations\n","chain = (\n","    {\n","        \"context\": itemgetter(\"question\") | retriever,\n","        \"question\": itemgetter(\"question\"),\n","    }\n","    | prompt\n","    | model\n","    | parser\n",")"],"metadata":{"id":"jh4g4GZJMFqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#posting questions\n","questions = [\n","    \"provide finanacial analysis as underwriter in financial company by going to complete context that has in company annual reports\"\n","    #\"how is the revenue growth of company in 2023\"\n","]\n","\n","for question in questions:\n","    print(f\"Question: {question}\")\n","    print(f\"Answer: {chain.invoke({'question': question})}\")\n","    print()"],"metadata":{"id":"Q-vOXzWzMHZt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGXiEAjASqQDmNmxiyRGM5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}